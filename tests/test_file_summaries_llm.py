"""
File Summaries ê¸°ëŠ¥ LLM ëª¨ë“œ í…ŒìŠ¤íŠ¸

ì‹¤ì œ OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ìš”ì•½ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import sys
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

sys.path.append('.')

from langchain_openai import ChatOpenAI
from domain.langgraph.nodes.change_analyzer_node import change_analyzer_node
from domain.langgraph.nodes.document_generator_node import document_generator_node
from domain.langgraph.document_state import DocumentState


def test_file_summaries_with_llm():
    """LLMì„ ì‚¬ìš©í•œ íŒŒì¼ ìš”ì•½ ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª Test: File Summaries with LLM")
    print("=" * 70)
    
    # OpenAI API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEY not found in environment variables")
        return
    
    print(f"âœ… API Key found: {api_key[:8]}...")
    
    # LLM ì´ˆê¸°í™”
    llm = ChatOpenAI(
        api_key=api_key,
        model="gpt-4o-mini",
        temperature=0.1
    )
    print("âœ… LLM initialized")
    
    # ì‹¤ì œ ì½”ë“œ ë³€ê²½ì‚¬í•­ ì‹œë®¬ë ˆì´ì…˜
    state: DocumentState = {
        "code_change_id": 1,
        "status": "analyzing",
        "changed_files": [
            "src/api/payment_router.py",
            "src/services/stripe_service.py",
            "src/models/payment_schema.py",
            "tests/test_payment.py",
            "README.md"
        ],
        "diff_content": """
diff --git a/src/api/payment_router.py b/src/api/payment_router.py
index 1234567..abcdefg 100644
--- a/src/api/payment_router.py
+++ b/src/api/payment_router.py
@@ -1,5 +1,30 @@
 from fastapi import APIRouter, Depends, HTTPException
+from src.services.stripe_service import StripeService
+from src.models.payment_schema import PaymentRequest, PaymentResponse
 
 router = APIRouter(prefix="/api/payment", tags=["payment"])
+
+@router.post("/create", response_model=PaymentResponse)
+async def create_payment(
+    payment: PaymentRequest,
+    stripe_service: StripeService = Depends()
+):
+    \"\"\"
+    Create a new payment with Stripe integration
+    
+    Args:
+        payment: Payment request with amount and currency
+        stripe_service: Injected Stripe service
+        
+    Returns:
+        PaymentResponse with payment intent ID and status
+    \"\"\"
+    try:
+        result = await stripe_service.create_payment_intent(
+            amount=payment.amount,
+            currency=payment.currency
+        )
+        return PaymentResponse(
+            payment_id=result.id,
+            status=result.status,
+            client_secret=result.client_secret
+        )
+    except Exception as e:
+        raise HTTPException(status_code=400, detail=str(e))

diff --git a/src/services/stripe_service.py b/src/services/stripe_service.py
new file mode 100644
index 0000000..2345678
--- /dev/null
+++ b/src/services/stripe_service.py
@@ -0,0 +1,25 @@
+import stripe
+from typing import Dict, Any
+
+class StripeService:
+    \"\"\"Stripe payment processing service\"\"\"
+    
+    def __init__(self, api_key: str):
+        stripe.api_key = api_key
+        
+    async def create_payment_intent(
+        self, 
+        amount: int, 
+        currency: str = "usd"
+    ) -> Any:
+        \"\"\"
+        Create a Stripe payment intent
+        
+        Args:
+            amount: Amount in cents
+            currency: Currency code (default: usd)
+            
+        Returns:
+            Stripe PaymentIntent object
+        \"\"\"
+        return stripe.PaymentIntent.create(
+            amount=amount,
+            currency=currency,
+            payment_method_types=["card"]
+        )

diff --git a/src/models/payment_schema.py b/src/models/payment_schema.py
index 3456789..bcdefgh 100644
--- a/src/models/payment_schema.py
+++ b/src/models/payment_schema.py
@@ -1,5 +1,20 @@
 from pydantic import BaseModel, Field
+from typing import Optional
 
 class PaymentRequest(BaseModel):
-    pass
+    amount: int = Field(..., description="Payment amount in cents", gt=0)
+    currency: str = Field(default="usd", description="Currency code")
+    
+    class Config:
+        json_schema_extra = {
+            "example": {
+                "amount": 1000,
+                "currency": "usd"
+            }
+        }
+
+class PaymentResponse(BaseModel):
+    payment_id: str
+    status: str
+    client_secret: Optional[str] = None
        """,
        "code_change": {
            "commit_sha": "abc123def456",
            "commit_message": "feat: Implement Stripe payment integration with create payment endpoint"
        }
    }
    
    print("\nğŸ“‹ Running change_analyzer_node with LLM...")
    print(f"  Changed files: {len(state['changed_files'])}")
    print(f"  Diff size: {len(state['diff_content'])} chars")
    
    # Change Analyzer ì‹¤í–‰ (LLM ëª¨ë“œ)
    result_state = change_analyzer_node(state, llm=llm, use_mock=False)
    
    print(f"\nâœ… Analysis complete!")
    print(f"  Status: {result_state.get('status')}")
    print(f"  Has file_change_summaries: {'file_change_summaries' in result_state}")
    
    if "file_change_summaries" in result_state:
        summaries = result_state["file_change_summaries"]
        print(f"  Number of summaries: {len(summaries)}")
        
        print(f"\nğŸ“ LLM-Generated File Summaries:")
        print("-" * 70)
        
        for i, summary in enumerate(summaries, 1):
            print(f"\n{i}. ğŸ“„ {summary['file']}")
            print(f"   Priority: {summary['priority']}")
            print(f"   Change Type: {summary['change_type']}")
            print(f"   Summary: {summary['summary']}")
    
    # Analysis result í™•ì¸
    if "analysis_result" in result_state:
        print(f"\nğŸ“Š Analysis Result:")
        print("-" * 70)
        print(result_state["analysis_result"])
    
    # Target sections í™•ì¸
    if "target_doc_sections" in result_state:
        print(f"\nğŸ¯ Target Doc Sections:")
        print(f"   {result_state['target_doc_sections']}")
    
    # ê²€ì¦
    assert "file_change_summaries" in result_state, "file_change_summaries not generated!"
    assert len(result_state["file_change_summaries"]) == 5, "Should have 5 file summaries"
    
    # ìš°ì„ ìˆœìœ„ ê²€ì¦
    summaries = result_state["file_change_summaries"]
    high_priority = [s for s in summaries if s['priority'] == 'high']
    medium_priority = [s for s in summaries if s['priority'] == 'medium']
    low_priority = [s for s in summaries if s['priority'] == 'low']
    
    print(f"\nğŸ“Š Priority Distribution:")
    print(f"   High: {len(high_priority)} files")
    for s in high_priority:
        print(f"     - {s['file']}")
    print(f"   Medium: {len(medium_priority)} files")
    for s in medium_priority:
        print(f"     - {s['file']}")
    print(f"   Low: {len(low_priority)} files")
    for s in low_priority:
        print(f"     - {s['file']}")
    
    print("\nâœ… All assertions passed!")
    return result_state


def test_document_generator_with_llm():
    """LLMì„ ì‚¬ìš©í•œ ë¬¸ì„œ ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\n\nğŸ§ª Test: Document Generator with LLM")
    print("=" * 70)
    
    # OpenAI API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEY not found")
        return
    
    # LLM ì´ˆê¸°í™”
    llm = ChatOpenAI(
        api_key=api_key,
        model="gpt-4o-mini",
        temperature=0.1
    )
    
    # ë¨¼ì € change_analyzerë¡œ file_summaries ìƒì„±
    print("\nğŸ“‹ Step 1: Generating file summaries with LLM...")
    
    initial_state: DocumentState = {
        "code_change_id": 1,
        "status": "analyzing",
        "changed_files": [
            "src/api/auth_router.py",
            "src/services/jwt_service.py"
        ],
        "diff_content": """
diff --git a/src/api/auth_router.py b/src/api/auth_router.py
+@router.post("/login")
+def login(credentials: LoginRequest):
+    token = jwt_service.generate_token(credentials.username)
+    return {"access_token": token}

diff --git a/src/services/jwt_service.py b/src/services/jwt_service.py
+def generate_token(username: str) -> str:
+    return jwt.encode({"sub": username}, SECRET_KEY)
        """,
        "code_change": {
            "commit_sha": "xyz789",
            "commit_message": "Add JWT authentication system"
        }
    }
    
    analyzed_state = change_analyzer_node(initial_state, llm=llm, use_mock=False)
    
    print(f"âœ… File summaries generated: {len(analyzed_state.get('file_change_summaries', []))}")
    
    # ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
    print("\nğŸ“‹ Step 2: Generating document with LLM...")
    
    analyzed_state.update({
        "should_update": True,
        "existing_document": {
            "content": """# API Documentation

## Overview
FastAPI application for user management.

## Modules

### User Management
- User CRUD operations
- Profile management

## Changelog
- 2024-01-01: Initial version
"""
        },
        "target_doc_sections": ["modules", "changelog"]
    })
    
    final_state = document_generator_node(analyzed_state, llm=llm, use_mock=False)
    
    print(f"\nâœ… Document generation complete!")
    print(f"  Status: {final_state.get('status')}")
    print(f"  Document length: {len(final_state.get('document_content', ''))} chars")
    
    if "document_content" in final_state:
        print(f"\nğŸ“„ Generated Document:")
        print("=" * 70)
        print(final_state["document_content"])
        print("=" * 70)
    
    if "document_summary" in final_state:
        print(f"\nğŸ“ Document Summary:")
        print(final_state["document_summary"])
    
    assert "document_content" in final_state, "Document not generated!"
    assert final_state["status"] == "saving", "Status should be 'saving'"
    
    print("\nâœ… All assertions passed!")
    return final_state


def test_full_integration_with_llm():
    """ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸ (LLM ëª¨ë“œ)"""
    print("\n\nğŸ§ª Test: Full Integration with LLM")
    print("=" * 70)
    
    # API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEY not found")
        return
    
    print("âœ… Starting full integration test with real LLM...")
    
    # LLM ì´ˆê¸°í™”
    llm = ChatOpenAI(
        api_key=api_key,
        model="gpt-4o-mini",
        temperature=0.1
    )
    
    # ë³µì¡í•œ ë³€ê²½ì‚¬í•­ ì‹œë®¬ë ˆì´ì…˜
    state: DocumentState = {
        "code_change_id": 1,
        "status": "analyzing",
        "should_update": True,
        "changed_files": [
            "src/api/payment_router.py",
            "src/services/payment_service.py",
            "src/models/payment_schema.py",
            "tests/test_payment.py"
        ],
        "diff_content": "+" * 500,  # Large diff
        "existing_document": {
            "content": """# Payment System Documentation

## Overview
Payment processing system

## Architecture
Basic structure

## Modules
Initial modules

## Changelog
- Initial version
"""
        },
        "code_change": {
            "commit_sha": "abc123",
            "commit_message": "feat: Add Stripe integration with webhook support"
        }
    }
    
    print("\nğŸ“‹ Step 1: Analyzing changes with LLM...")
    analyzed_state = change_analyzer_node(state, llm=llm, use_mock=False)
    
    print(f"  âœ… Analysis complete")
    print(f"     File summaries: {len(analyzed_state.get('file_change_summaries', []))}")
    print(f"     Target sections: {analyzed_state.get('target_doc_sections', [])}")
    
    print("\nğŸ“‹ Step 2: Generating document with LLM...")
    final_state = document_generator_node(analyzed_state, llm=llm, use_mock=False)
    
    print(f"  âœ… Document generated")
    print(f"     Status: {final_state['status']}")
    print(f"     Length: {len(final_state.get('document_content', ''))} chars")
    
    # ê²°ê³¼ ì¶œë ¥
    if "file_change_summaries" in analyzed_state:
        print(f"\nğŸ“ File Summaries (LLM-generated):")
        for s in analyzed_state["file_change_summaries"]:
            print(f"  - {s['file']} ({s['priority']}): {s['summary'][:60]}...")
    
    if "document_content" in final_state:
        print(f"\nğŸ“„ Final Document Preview:")
        print("-" * 70)
        print(final_state["document_content"][:800])
        print("\n... (truncated)")
        print("-" * 70)
    
    # ê²€ì¦
    assert "file_change_summaries" in analyzed_state
    assert "document_content" in final_state
    assert final_state["status"] == "saving"
    
    print("\nâœ… Full integration test passed!")
    print("\n" + "=" * 70)
    print("ğŸ‰ All LLM tests completed successfully!")


if __name__ == "__main__":
    try:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        print("\nğŸš€ Starting LLM Mode Tests")
        print("=" * 70)
        
        test_file_summaries_with_llm()
        test_document_generator_with_llm()
        test_full_integration_with_llm()
        
    except Exception as e:
        print(f"\nâŒ Error occurred: {e}")
        import traceback
        traceback.print_exc()
